{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/test.csv', encoding='iso-8859-1')\n",
    "\n",
    "train_data = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/train.csv', parse_dates=['Date'], low_memory=False)\n",
    "\n",
    "# Загрузка данных из файла store.csv\n",
    "store_data = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/store.csv', encoding='iso-8859-1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_form = train_data.copy()\n",
    "\n",
    "df_form.replace({' - ': np.nan, '\\\\N': np.nan, 'NaN': np.nan}, inplace=True)\n",
    "df_form = df_form.dropna()\n",
    "\n",
    "#print(df_form.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96a602ea074fd22c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Описание количественных переменных:\")\n",
    "print(df_form.describe())\n",
    "\n",
    "\n",
    "# Числовые столбцы\n",
    "numeric_columns = ['Sales', 'Customers']\n",
    "\n",
    "# Визуализация числовых столбцов\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.histplot(df_form[col], bins=50, kde=True)\n",
    "    plt.title(f'Распределение {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Визуализация категориальных столбцов\n",
    "categorical_columns = [ 'StateHoliday', 'DayOfWeek',  'Open', 'Promo' , 'SchoolHoliday']\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    plt.subplot(1, len(categorical_columns), i+1)\n",
    "    sns.countplot(x=df_form[col])\n",
    "    plt.title(f'Распределение {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выбираем только числовые столбцы для корреляционного анализа\n",
    "numeric_df = df_form.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# Удаляем строки с пропущенными значениями в числовых столбцах\n",
    "numeric_df = numeric_df.dropna()\n",
    "\n",
    "# Проверка корреляции между числовыми признаками\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = numeric_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Корреляционная матрица числовых признаков')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b5b3e183cc42d8a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Факторизация категориальных столбцов\n",
    "categorical_column = [ 'StateHoliday', 'DayOfWeek',  'Open', 'Promo' , 'SchoolHoliday']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_df_list = []\n",
    "\n",
    "for name in categorical_column:\n",
    "    # Применение OneHotEncoder к целевому столбцу\n",
    "    encoded_columns = encoder.fit_transform(df_form[[name]])\n",
    "    # Преобразование закодированных данных в DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out([name]))\n",
    "    encoded_df_list.append(encoded_df)\n",
    "\n",
    "# Объединение закодированных столбцов с исходным DataFrame (удалив при этом исходные столбцы)\n",
    "df_form = df_form.drop(columns=categorical_column)\n",
    "df_form = pd.concat([df_form] + encoded_df_list, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d153e929a45bf09",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Добавление временных признаков в DataFrame\n",
    "df_form['Year'] = df_form['Date'].dt.year\n",
    "df_form['Month'] = df_form['Date'].dt.month\n",
    "df_form['Day'] = df_form['Date'].dt.day\n",
    "\n",
    "# Убедимся, что данные добавлены корректно\n",
    "print(df_form[['Date', 'Year', 'Month', 'Day']].head())\n",
    "\n",
    "# 2. Обновление списка категориальных столбцов для кодирования\n",
    "categorical_column = ['StateHoliday', 'SchoolHoliday', 'Promo', 'Open', 'Year', 'Month']\n",
    "\n",
    "# Убедитесь, что все столбцы из списка есть в DataFrame\n",
    "categorical_column = [col for col in categorical_column if col in df_form.columns]\n",
    "\n",
    "# 3. Факторизация категориальных столбцов\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_df_list = []\n",
    "\n",
    "for name in categorical_column:\n",
    "    # Применение OneHotEncoder к целевому столбцу\n",
    "    encoded_columns = encoder.fit_transform(df_form[[name]])\n",
    "    # Преобразование закодированных данных в DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out([name]))\n",
    "    encoded_df_list.append(encoded_df)\n",
    "\n",
    "# Объединение закодированных столбцов с исходным DataFrame (удалив при этом исходные столбцы)\n",
    "df_form = df_form.drop(columns=categorical_column)\n",
    "df_form = pd.concat([df_form] + encoded_df_list, axis=1)\n",
    "\n",
    "# 4. Удаление столбца с датой перед моделированием и анализом корреляций\n",
    "df_form = df_form.drop(columns=['Date'])\n",
    "\n",
    "# Убедимся, что результат корректный\n",
    "print(df_form.head())\n",
    "\n",
    "# Далее продолжаем анализ данных и моделирование...\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fbae0660b13262a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Определяем целевую переменную (в данном случае, допустим, что 'Sales' - это целевая переменная)\n",
    "target = 'Sales'\n",
    "\n",
    "# Разделяем признаки (X) и целевую переменную (y)\n",
    "X = df_form.drop(columns=[target])\n",
    "Y = df_form[target]\n",
    "\n",
    "# Разделяем данные на тренировочный и тестовый наборы\n",
    "# Например, тестовый набор составит 20% от всех данных\n",
    "train_points, test_points, train_values, test_values = train_test_split(X, Y, test_size = 0.2)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7da69aeaa679e8b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(train_points)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "380ff7e485a4777",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Создаем модель линейной регрессии\n",
    "model = LinearRegression()\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "model.fit(train_points, train_values)\n",
    "\n",
    "# Прогнозируем значения на тестовом наборе данных\n",
    "lr_predict = model.predict(test_points)\n",
    "\n",
    "# Оцениваем модель с использованием метрик MAE, MSE, RMSE и R^2\n",
    "mae = mean_absolute_error(test_values, lr_predict)\n",
    "mse = mean_squared_error(test_values, lr_predict)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(test_values, lr_predict)\n",
    "\n",
    "# Выводим значения MAE, MSE, RMSE и R^2\n",
    "print(f\"Среднее абсолютное отклонение (MAE) на тестовых данных: {mae}\")\n",
    "print(f\"Среднеквадратичная ошибка (MSE) на тестовых данных: {mse}\")\n",
    "print(f\"Корень средней квадратичной ошибки (RMSE) на тестовых данных: {rmse}\")\n",
    "print(f\"Коэффициент детерминации (R^2) на тестовых данных: {r2}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14e8f4592195994a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Создаем и обучаем модель XGBoost\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                          max_depth=5, alpha=10, n_estimators=100)\n",
    "xg_reg.fit(train_points, train_values)\n",
    "\n",
    "# Прогнозируем значения на тестовом наборе данных\n",
    "xgb_predict = xg_reg.predict(test_points)\n",
    "\n",
    "# Оцениваем модель с использованием MAE, MSE, RMSE и R^2\n",
    "mae_xgb = mean_absolute_error(test_values, xgb_predict)\n",
    "mse_xgb = mean_squared_error(test_values, xgb_predict)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(test_values, xgb_predict)\n",
    "\n",
    "# Выводим значения MAE, MSE, RMSE и R^2\n",
    "print(f\"Среднее абсолютное отклонение (MAE) на тестовых данных: {mae_xgb}\")\n",
    "print(f\"Среднеквадратичная ошибка (MSE) на тестовых данных: {mse_xgb}\")\n",
    "print(f\"Корень средней квадратичной ошибки (RMSE) на тестовых данных: {rmse_xgb}\")\n",
    "print(f\"Коэффициент детерминации (R^2) на тестовых данных: {r2_xgb}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1e39ccddef67531",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Создаем модель случайного леса с оптимизированными параметрами\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50,  \n",
    "    max_depth=10,  # Ограничение глубины деревьев для ускорения обучения\n",
    "    n_jobs=-1,  # все доступные ядра процессора\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "rf_model.fit(train_points, train_values)\n",
    "\n",
    "# Прогнозируем значения на тестовом наборе данных\n",
    "rf_predict = rf_model.predict(test_points)\n",
    "\n",
    "# Оцениваем модель с использованием MAE, MSE, RMSE и R^2\n",
    "mae_rf = mean_absolute_error(test_values, rf_predict)\n",
    "mse_rf = mean_squared_error(test_values, rf_predict)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(test_values, rf_predict)\n",
    "\n",
    "# Выводим оценки\n",
    "print(f\"Среднее абсолютное отклонение (MAE) на тестовых данных (RandomForest): {mae_rf}\")\n",
    "print(f\"Среднеквадратичная ошибка (MSE) на тестовых данных (RandomForest): {mse_rf}\")\n",
    "print(f\"Корень средней квадратичной ошибки (RMSE) на тестовых данных (RandomForest): {rmse_rf}\")\n",
    "print(f\"Коэффициент детерминации (R^2) на тестовых данных (RandomForest): {r2_rf}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8e80184d60be466",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Функция для преобразования данных в формат CNN\n",
    "def preprocess_for_cnn(data, height, width):\n",
    "    return data.reshape(-1, height, width, 1)\n",
    "\n",
    "# Преобразование данных\n",
    "train_points_cnn = preprocess_for_cnn(train_points_np, height, width)\n",
    "test_points_cnn = preprocess_for_cnn(test_points_np, height, width)\n",
    "\n",
    "# Определение и компиляция модели CNN\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(height, width, 1)),\n",
    "    MaxPooling2D(pool_size=(1, 2)),  # Изменено на (1, 2) чтобы избежать отрицательных размеров\n",
    "    Dropout(0.25),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(1, 2)),  # Изменено на (1, 2)\n",
    "    Dropout(0.25),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(1, 2)),  # Изменено на (1, 2)\n",
    "    Dropout(0.25),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # Для регрессии\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Определение Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Обучение модели\n",
    "results = cnn_model.fit(\n",
    "    train_points_cnn, train_values,\n",
    "    epochs=5,  # Увеличено количество эпох\n",
    "    batch_size=32,\n",
    "    validation_data=(test_points_cnn, test_values),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Предсказание\n",
    "cnn_predict = cnn_model.predict(test_points_cnn)\n",
    "\n",
    "# Расчет метрик\n",
    "mae_cnn = mean_absolute_error(test_values, cnn_predict)\n",
    "rmse_cnn = np.sqrt(mean_squared_error(test_values, cnn_predict))\n",
    "mse_cnn = mean_squared_error(test_values, cnn_predict)\n",
    "r2_cnn = r2_score(test_values, cnn_predict)\n",
    "\n",
    "# Вывод значений MAE, RMSE, MSE и R2\n",
    "print(f\"Среднее абсолютное отклонение (MAE) на тестовых данных (CNN): {mae_cnn}\")\n",
    "print(f\"Корень средней квадратичной ошибки (RMSE) на тестовых данных (CNN): {rmse_cnn}\")\n",
    "print(f\"Среднеквадратичная ошибка (MSE) на тестовых данных (CNN): {mse_cnn}\")\n",
    "print(f\"Коэффициент детерминации (R2) на тестовых данных (CNN): {r2_cnn}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "befff721288c9bba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/train.csv', parse_dates=['Date'], low_memory=False)\n",
    "\n",
    "# Преобразование даты в datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Обработка пропусков и ненужных значений\n",
    "df = df.fillna(0)  # Или другой метод обработки пропусков\n",
    "\n",
    "# Добавление дополнительных признаков (например, день недели, месяц)\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "# Преобразование категориальных данных в числовые\n",
    "df = pd.get_dummies(df, columns=['StateHoliday'])\n",
    "\n",
    "# Сортировка данных по дате\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Удаление ненужных столбцов\n",
    "df = df[['Store', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c', 'SchoolHoliday', 'DayOfWeek', 'Month']]\n",
    "\n",
    "# Нормализация признаков\n",
    "scaler = StandardScaler()\n",
    "df[['Sales', 'Customers', 'Open', 'Promo', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c', 'SchoolHoliday', 'DayOfWeek', 'Month']] = scaler.fit_transform(df[['Sales', 'Customers', 'Open', 'Promo', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c', 'SchoolHoliday', 'DayOfWeek', 'Month']])\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "seq_length = 30  # Длина окна\n",
    "\n",
    "# Преобразование данных в массивы для CNN\n",
    "train_sequences = create_sequences(train_df.values, seq_length)\n",
    "test_sequences = create_sequences(test_df.values, seq_length)\n",
    "\n",
    "X_train = train_sequences[:, :-1]\n",
    "y_train = train_sequences[:, -1, 1]  # Sales is the second column\n",
    "X_test = test_sequences[:, :-1]\n",
    "y_test = test_sequences[:, -1, 1]\n",
    "\n",
    "# Преобразование типов\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Создание модели\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))  # Предсказание объема продаж\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Прогнозирование на тестовых данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Вычисление метрик\n",
    "mae_cnn = mean_absolute_error(y_test, y_pred)\n",
    "mse_cnn = mean_squared_error(y_test, y_pred)\n",
    "rmse_cnn = np.sqrt(mse_cnn)\n",
    "r2_cnn = r2_score(y_test, y_pred)\n",
    "\n",
    "# Вывод значений метрик\n",
    "print(f\"Среднее абсолютное отклонение (MAE) на тестовых данных (CNN): {mae_cnn}\")\n",
    "print(f\"Корень средней квадратичной ошибки (RMSE) на тестовых данных (CNN): {rmse_cnn}\")\n",
    "print(f\"Среднеквадратичная ошибка (MSE) на тестовых данных (CNN): {mse_cnn}\")\n",
    "print(f\"Коэффициент детерминации (R2) на тестовых данных (CNN): {r2_cnn}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcf79f17dd3add36",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "53a37fcf3776d267"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
