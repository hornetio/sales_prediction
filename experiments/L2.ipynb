{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Store'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 32\u001B[0m\n\u001B[0;32m     30\u001B[0m store_data \u001B[38;5;241m=\u001B[39m store_data\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     31\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(train_data, store_data, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStore\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 32\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mStore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39minfo)\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   5433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[0;32m   5434\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5435\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5442\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   5443\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5444\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5445\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[0;32m   5446\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5579\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[0;32m   5580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 5581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5583\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5587\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5588\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5589\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4786\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   4787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4788\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4790\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[0;32m   4791\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[1;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[0;32m   4828\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   4829\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4830\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4831\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[0;32m   4833\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[0;32m   4834\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001B[0m, in \u001B[0;36mIndex.drop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   7068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m   7069\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 7070\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   7071\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[0;32m   7072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Store'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/test.csv', encoding='iso-8859-1',na_values=[''], keep_default_na=False)\n",
    "\n",
    "train_data = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/train.csv', parse_dates=['Date'], low_memory=False, na_values=[''], keep_default_na=False)\n",
    "\n",
    "# Загрузка данных из файла store.csv\n",
    "store_data = pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/store.csv', encoding='iso-8859-1',na_values=[''], keep_default_na=False)\n",
    "\n",
    "\n",
    "# Заменяем NaN на '0'\n",
    "train_data = train_data.fillna(\"0\")\n",
    "test_data = test_data.fillna(\"0\")\n",
    "store_data = store_data.fillna(\"0\")\n",
    "df = pd.merge(train_data, store_data, on='Store')\n",
    "df = df.drop('Store')\n",
    "print(df.columns)\n",
    "print(df.info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T19:48:53.030762500Z",
     "start_time": "2024-08-22T19:48:44.262230300Z"
    }
   },
   "id": "3a771acf775d665d",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удаление лишних столбцов"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e875e03b4af8d5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method DataFrame.info of        BOROUGH   NEIGHBORHOOD                      BUILDING CLASS CATEGORY  \\\n0            1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n1            1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n2            1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n3            1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n4            1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n...        ...            ...                                          ...   \n84543        5        WOODROW  02 TWO FAMILY DWELLINGS                       \n84544        5        WOODROW  02 TWO FAMILY DWELLINGS                       \n84545        5        WOODROW  02 TWO FAMILY DWELLINGS                       \n84546        5        WOODROW  22 STORE BUILDINGS                            \n84547        5        WOODROW  35 INDOOR PUBLIC AND CULTURAL FACILITIES      \n\n      TAX CLASS AT PRESENT EASE-MENT BUILDING CLASS AT PRESENT  \\\n0                       2A                                  C2   \n1                        2                                  C7   \n2                        2                                  C7   \n3                       2B                                  C4   \n4                       2A                                  C2   \n...                    ...       ...                       ...   \n84543                    1                                  B9   \n84544                    1                                  B9   \n84545                    1                                  B2   \n84546                    4                                  K6   \n84547                    4                                  P9   \n\n       RESIDENTIAL UNITS  COMMERCIAL UNITS  TOTAL UNITS LAND SQUARE FEET  \\\n0                      5                 0            5             1633   \n1                     28                 3           31             4616   \n2                     16                 1           17             2212   \n3                     10                 0           10             2272   \n4                      6                 0            6             2369   \n...                  ...               ...          ...              ...   \n84543                  2                 0            2             2400   \n84544                  2                 0            2             2498   \n84545                  2                 0            2             4000   \n84546                  0                 7            7           208033   \n84547                  0                 1            1            10796   \n\n      GROSS SQUARE FEET  YEAR BUILT  TAX CLASS AT TIME OF SALE  \\\n0                  6440        1900                          2   \n1                 18690        1900                          2   \n2                  7803        1900                          2   \n3                  6794        1913                          2   \n4                  4615        1900                          2   \n...                 ...         ...                        ...   \n84543              2575        1998                          1   \n84544              2377        1998                          1   \n84545              1496        1925                          1   \n84546             64117        2001                          4   \n84547              2400        2006                          4   \n\n      BUILDING CLASS AT TIME OF SALE SALE PRICE            SALE DATE  \n0                                 C2    6625000  2017-07-19 00:00:00  \n1                                 C7        -    2016-12-14 00:00:00  \n2                                 C7        -    2016-12-09 00:00:00  \n3                                 C4    3936272  2016-09-23 00:00:00  \n4                                 C2    8000000  2016-11-17 00:00:00  \n...                              ...        ...                  ...  \n84543                             B9     450000  2016-11-28 00:00:00  \n84544                             B9     550000  2017-04-21 00:00:00  \n84545                             B2     460000  2017-07-05 00:00:00  \n84546                             K6   11693337  2016-12-21 00:00:00  \n84547                             P9      69300  2016-10-27 00:00:00  \n\n[84548 rows x 16 columns]>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_read.copy()\n",
    "\n",
    "\n",
    "# Определение категориальных и числовых признаков\n",
    "categorical_features = ['StateHoliday', 'StoreType', 'Assortment', 'PromoInterval']\n",
    "numerical_features = ['Sales', 'Customers', 'Open', 'Promo', 'SchoolHoliday', \n",
    "                      'CompetitionDistance', 'CompetitionOpenSinceMonth', \n",
    "                      'Promo2', 'Promo2SinceWeek'\n",
    "                      ]\n",
    "\n",
    "date_column = ['Promo2SinceYear', 'CompetitionOpenSinceYear', \"Date\"]\n",
    "\n",
    "df.info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T03:28:51.148416700Z",
     "start_time": "2024-06-05T03:28:51.132004200Z"
    }
   },
   "id": "50b27ff7a7329de4",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Форматирование данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33f9d0e5a926a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_form = df.copy()\n",
    "\n",
    "\n",
    "df_form.replace({' - ': np.nan, '\\\\N': np.nan, 'NaN': np.nan}, inplace=True)\n",
    "df_form = df_form.dropna()\n",
    "\n",
    "# Факторизация категориальных столбцов\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_df_list = []\n",
    "\n",
    "for name in categorical_column:\n",
    "    # Применение OneHotEncoder к целевому столбцу\n",
    "    encoded_columns = encoder.fit_transform(df_form[[name]])\n",
    "    # Преобразование закодированных данных в DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out([name]))\n",
    "    encoded_df_list.append(encoded_df)\n",
    "\n",
    "# Объединение закодированных столбцов с исходным DataFrame (удалив при этом исходные столбцы)\n",
    "df_form = df_form.drop(columns=categorical_column)\n",
    "df_form = pd.concat([df_form] + encoded_df_list, axis=1)\n",
    "\n",
    "# Приведение столбцов с датами, к виду отрезка времени до сегодняшней даты\n",
    "# Преобразование столбца 'SALE DATE' в формат datetime\n",
    "df_form['SALE DATE'] = pd.to_datetime(df_form['SALE DATE'])\n",
    "\n",
    "# Извлечение года из столбца 'SALE DATE'\n",
    "df_form['SALE YEAR'] = df_form['SALE DATE'].dt.year\n",
    "\n",
    "df_form['YEARS DIFFERENCE'] = df_form['SALE YEAR'] - df_form['YEAR BUILT']\n",
    "df_form.drop(columns=['YEAR BUILT', 'SALE DATE', 'SALE YEAR'], inplace=True)\n",
    "\n",
    "#Приведение всех числовых столбцов к типу int\n",
    "for column in num_column :\n",
    "    df_form[column] = pd.to_numeric(df_form[column], errors='coerce')\n",
    "\n",
    "df_form = df_form.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T03:28:57.656544Z",
     "start_time": "2024-06-05T03:28:56.074973800Z"
    }
   },
   "id": "f0382fe3dcfabd",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создание тестового и тренировочного датасетов\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18a3a9fd4e7883d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Y = df_form['SALE PRICE']\n",
    "X = df_form.drop(['SALE PRICE'], axis = 1)\n",
    "X = scaler.fit_transform(X)\n",
    "train_points, test_points, train_values, test_values = train_test_split(X, Y, test_size = 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T03:29:00.642766Z",
     "start_time": "2024-06-05T03:28:59.272448100Z"
    }
   },
   "id": "c9b24f63694603b7",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создание модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e828332419ff092e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m386/386\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 1322006.2500 - val_loss: 1069307.6250\n",
      "Epoch 2/5\n",
      "\u001B[1m386/386\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 1149811.6250 - val_loss: 947153.9375\n",
      "Epoch 3/5\n",
      "\u001B[1m386/386\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 1121754.6250 - val_loss: 897799.2500\n",
      "Epoch 4/5\n",
      "\u001B[1m386/386\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 968326.8750 - val_loss: 876338.1875\n",
      "Epoch 5/5\n",
      "\u001B[1m386/386\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 934508.6250 - val_loss: 862617.3750\n",
      "\u001B[1m302/302\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 912us/step\n",
      "862617.5208734794\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Определение и компиляция модели\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(17, activation='relu', input_shape=(train_points.shape[1],)))\n",
    "nn_model.add(Dense(15, activation='relu'))\n",
    "nn_model.add(Dense(15, activation='relu'))\n",
    "nn_model.add(Dense(1))\n",
    "\n",
    "nn_model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "# Обучение модели\n",
    "results = nn_model.fit(\n",
    "    train_points, train_values,\n",
    "    epochs=5,\n",
    "    batch_size=100,\n",
    "    validation_data=(test_points, test_values)\n",
    ")\n",
    "\n",
    "# Предсказание\n",
    "nn_predict = nn_model.predict(test_points)\n",
    "\n",
    "# Удаление NaN и бесконечных значений перед расчетом mean_absolute_error\n",
    "test_values_clean = test_values[~np.isnan(nn_predict).flatten() & ~np.isinf(nn_predict).flatten()]\n",
    "nn_predict_clean = nn_predict[~np.isnan(nn_predict).flatten() & ~np.isinf(nn_predict).flatten()]\n",
    "\n",
    "# Расчет mean_absolute_error\n",
    "print(mean_absolute_error(test_values_clean, nn_predict_clean))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T03:29:14.527514700Z",
     "start_time": "2024-06-05T03:29:08.902457700Z"
    }
   },
   "id": "8121d6b688326ca0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.557537518842349e+18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(train_points, train_values)\n",
    "lr_predict = model.predict(test_points)\n",
    "print(mean_absolute_error(test_values, lr_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T03:29:21.153715100Z",
     "start_time": "2024-06-05T03:29:16.769442900Z"
    }
   },
   "id": "ff73b74bf29c0f77",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849064.600479972\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective = 'reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "xg_reg.fit(train_points, train_values)\n",
    "xgb_predict = xg_reg.predict(test_points)\n",
    "print(mean_absolute_error(test_values, xgb_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T03:29:23.090277600Z",
     "start_time": "2024-06-05T03:29:21.152710700Z"
    }
   },
   "id": "bb9c63d45a7867f0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "52d3c61085ccdec5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
