{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP4//2gy52wkz5ijU/4aw//",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hornetio/sales_prediction/blob/main/experiments/data_preproces_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "id": "J_RijViJvIuC",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:48.460568500Z",
     "start_time": "2024-08-24T10:39:48.316298300Z"
    }
   },
   "execution_count": 264,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/test.csv', parse_dates=['Date'], low_memory=False)\n",
    "train_df=pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/train.csv', parse_dates=['Date'], low_memory=False)\n",
    "add_df=pd.read_csv('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/Практика Нетодология/sales_prediction/Команда_11/store.csv', low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.203893400Z",
     "start_time": "2024-08-24T10:39:48.465571100Z"
    }
   },
   "execution_count": 265
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Первичная обработка NaN"
   ],
   "metadata": {
    "id": "xcwb5VQUvQWH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "add_df.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "0gWPg1bXmNTV",
    "outputId": "94f742db-66cb-407d-e552-78f2f68d53cf",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.215165800Z",
     "start_time": "2024-08-24T10:39:49.187463900Z"
    }
   },
   "execution_count": 266,
   "outputs": [
    {
     "data": {
      "text/plain": "Store                          0\nStoreType                      0\nAssortment                     0\nCompetitionDistance            3\nCompetitionOpenSinceMonth    354\nCompetitionOpenSinceYear     354\nPromo2                         0\nPromo2SinceWeek              544\nPromo2SinceYear              544\nPromoInterval                544\ndtype: int64"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "add_df.loc[add_df['Promo2'] == 0, ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']] = 0"
   ],
   "metadata": {
    "id": "utwKh3Ygmz0B",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.217179100Z",
     "start_time": "2024-08-24T10:39:49.202885900Z"
    }
   },
   "execution_count": 267,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from random import randint"
   ],
   "metadata": {
    "id": "HuZJ4bIysiNK",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.256847Z",
     "start_time": "2024-08-24T10:39:49.213670200Z"
    }
   },
   "execution_count": 268,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "add_df['CompetitionDistance'].fillna(add_df['CompetitionDistance'].max()+randint(-200,200), inplace=True)\n",
    "add_df['CompetitionOpenSinceMonth'].fillna(int(add_df['CompetitionOpenSinceMonth'].mean()+randint(-2,2)), inplace=True)\n",
    "add_df['CompetitionOpenSinceYear'].fillna(int(add_df['CompetitionOpenSinceYear'].mean()+randint(-5,5)), inplace=True)"
   ],
   "metadata": {
    "id": "w3cXcA5muwbl",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.259843200Z",
     "start_time": "2024-08-24T10:39:49.220185600Z"
    }
   },
   "execution_count": 269,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panfi\\AppData\\Local\\Temp\\ipykernel_11480\\3165722452.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  add_df['CompetitionDistance'].fillna(add_df['CompetitionDistance'].max()+randint(-200,200), inplace=True)\n",
      "C:\\Users\\panfi\\AppData\\Local\\Temp\\ipykernel_11480\\3165722452.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  add_df['CompetitionOpenSinceMonth'].fillna(int(add_df['CompetitionOpenSinceMonth'].mean()+randint(-2,2)), inplace=True)\n",
      "C:\\Users\\panfi\\AppData\\Local\\Temp\\ipykernel_11480\\3165722452.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  add_df['CompetitionOpenSinceYear'].fillna(int(add_df['CompetitionOpenSinceYear'].mean()+randint(-5,5)), inplace=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.merge(train_df, add_df, on='Store')"
   ],
   "metadata": {
    "id": "iFQBJul1S7LL",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.413516900Z",
     "start_time": "2024-08-24T10:39:49.231328600Z"
    }
   },
   "execution_count": 270,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvXW4EQ5uahh",
    "outputId": "40da8249-2c7c-4455-a2dc-4644e3c9a11e",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.670643700Z",
     "start_time": "2024-08-24T10:39:49.409518400Z"
    }
   },
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count    Dtype         \n",
      "---  ------                     --------------    -----         \n",
      " 0   Store                      1017209 non-null  int64         \n",
      " 1   DayOfWeek                  1017209 non-null  int64         \n",
      " 2   Date                       1017209 non-null  datetime64[ns]\n",
      " 3   Sales                      1017209 non-null  int64         \n",
      " 4   Customers                  1017209 non-null  int64         \n",
      " 5   Open                       1017209 non-null  int64         \n",
      " 6   Promo                      1017209 non-null  int64         \n",
      " 7   StateHoliday               1017209 non-null  object        \n",
      " 8   SchoolHoliday              1017209 non-null  int64         \n",
      " 9   StoreType                  1017209 non-null  object        \n",
      " 10  Assortment                 1017209 non-null  object        \n",
      " 11  CompetitionDistance        1017209 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  1017209 non-null  float64       \n",
      " 13  CompetitionOpenSinceYear   1017209 non-null  float64       \n",
      " 14  Promo2                     1017209 non-null  int64         \n",
      " 15  Promo2SinceWeek            1017209 non-null  float64       \n",
      " 16  Promo2SinceYear            1017209 non-null  float64       \n",
      " 17  PromoInterval              1017209 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(5), int64(8), object(4)\n",
      "memory usage: 139.7+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "7u68sYfIuh8u",
    "outputId": "02fcc159-8461-4c1f-f092-bf20afae56cc",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:49.727149300Z",
     "start_time": "2024-08-24T10:39:49.669638800Z"
    }
   },
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "Store                        0\nDayOfWeek                    0\nDate                         0\nSales                        0\nCustomers                    0\nOpen                         0\nPromo                        0\nStateHoliday                 0\nSchoolHoliday                0\nStoreType                    0\nAssortment                   0\nCompetitionDistance          0\nCompetitionOpenSinceMonth    0\nCompetitionOpenSinceYear     0\nPromo2                       0\nPromo2SinceWeek              0\nPromo2SinceYear              0\nPromoInterval                0\ndtype: int64"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "ueeJQ1PLup2b",
    "outputId": "ba384aa8-1430-4332-d18b-2312aee4e27d",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:50.210956600Z",
     "start_time": "2024-08-24T10:39:49.720146400Z"
    }
   },
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "              Store     DayOfWeek                           Date  \\\ncount  1.017209e+06  1.017209e+06                        1017209   \nmean   5.584297e+02  3.998341e+00  2014-04-11 01:30:42.846061824   \nmin    1.000000e+00  1.000000e+00            2013-01-01 00:00:00   \n25%    2.800000e+02  2.000000e+00            2013-08-17 00:00:00   \n50%    5.580000e+02  4.000000e+00            2014-04-02 00:00:00   \n75%    8.380000e+02  6.000000e+00            2014-12-12 00:00:00   \nmax    1.115000e+03  7.000000e+00            2015-07-31 00:00:00   \nstd    3.219087e+02  1.997391e+00                            NaN   \n\n              Sales     Customers          Open         Promo  SchoolHoliday  \\\ncount  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   1.017209e+06   \nmean   5.773819e+03  6.331459e+02  8.301067e-01  3.815145e-01   1.786467e-01   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00   \n25%    3.727000e+03  4.050000e+02  1.000000e+00  0.000000e+00   0.000000e+00   \n50%    5.744000e+03  6.090000e+02  1.000000e+00  0.000000e+00   0.000000e+00   \n75%    7.856000e+03  8.370000e+02  1.000000e+00  1.000000e+00   0.000000e+00   \nmax    4.155100e+04  7.388000e+03  1.000000e+00  1.000000e+00   1.000000e+00   \nstd    3.849926e+03  4.644117e+02  3.755392e-01  4.857586e-01   3.830564e-01   \n\n       CompetitionDistance  CompetitionOpenSinceMonth  \\\ncount         1.017209e+06               1.017209e+06   \nmean          5.613125e+03               6.516267e+00   \nmin           2.000000e+01               1.000000e+00   \n25%           7.100000e+02               5.000000e+00   \n50%           2.330000e+03               5.000000e+00   \n75%           6.910000e+03               9.000000e+00   \nmax           7.590300e+04               1.200000e+01   \nstd           8.499262e+03               2.847468e+00   \n\n       CompetitionOpenSinceYear        Promo2  Promo2SinceWeek  \\\ncount              1.017209e+06  1.017209e+06     1.017209e+06   \nmean               2.009742e+03  5.005638e-01     1.164767e+01   \nmin                1.900000e+03  0.000000e+00     0.000000e+00   \n25%                2.008000e+03  0.000000e+00     0.000000e+00   \n50%                2.012000e+03  1.000000e+00     1.000000e+00   \n75%                2.012000e+03  1.000000e+00     2.200000e+01   \nmax                2.015000e+03  1.000000e+00     5.000000e+01   \nstd                5.183775e+00  4.999999e-01     1.532393e+01   \n\n       Promo2SinceYear  \ncount     1.017209e+06  \nmean      1.007011e+03  \nmin       0.000000e+00  \n25%       0.000000e+00  \n50%       2.009000e+03  \n75%       2.012000e+03  \nmax       2.015000e+03  \nstd       1.005877e+03  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>Date</th>\n      <th>Sales</th>\n      <th>Customers</th>\n      <th>Open</th>\n      <th>Promo</th>\n      <th>SchoolHoliday</th>\n      <th>CompetitionDistance</th>\n      <th>CompetitionOpenSinceMonth</th>\n      <th>CompetitionOpenSinceYear</th>\n      <th>Promo2</th>\n      <th>Promo2SinceWeek</th>\n      <th>Promo2SinceYear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1017209</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n      <td>1.017209e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.584297e+02</td>\n      <td>3.998341e+00</td>\n      <td>2014-04-11 01:30:42.846061824</td>\n      <td>5.773819e+03</td>\n      <td>6.331459e+02</td>\n      <td>8.301067e-01</td>\n      <td>3.815145e-01</td>\n      <td>1.786467e-01</td>\n      <td>5.613125e+03</td>\n      <td>6.516267e+00</td>\n      <td>2.009742e+03</td>\n      <td>5.005638e-01</td>\n      <td>1.164767e+01</td>\n      <td>1.007011e+03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2013-01-01 00:00:00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2.000000e+01</td>\n      <td>1.000000e+00</td>\n      <td>1.900000e+03</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.800000e+02</td>\n      <td>2.000000e+00</td>\n      <td>2013-08-17 00:00:00</td>\n      <td>3.727000e+03</td>\n      <td>4.050000e+02</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>7.100000e+02</td>\n      <td>5.000000e+00</td>\n      <td>2.008000e+03</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.580000e+02</td>\n      <td>4.000000e+00</td>\n      <td>2014-04-02 00:00:00</td>\n      <td>5.744000e+03</td>\n      <td>6.090000e+02</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2.330000e+03</td>\n      <td>5.000000e+00</td>\n      <td>2.012000e+03</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.009000e+03</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.380000e+02</td>\n      <td>6.000000e+00</td>\n      <td>2014-12-12 00:00:00</td>\n      <td>7.856000e+03</td>\n      <td>8.370000e+02</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>6.910000e+03</td>\n      <td>9.000000e+00</td>\n      <td>2.012000e+03</td>\n      <td>1.000000e+00</td>\n      <td>2.200000e+01</td>\n      <td>2.012000e+03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.115000e+03</td>\n      <td>7.000000e+00</td>\n      <td>2015-07-31 00:00:00</td>\n      <td>4.155100e+04</td>\n      <td>7.388000e+03</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>7.590300e+04</td>\n      <td>1.200000e+01</td>\n      <td>2.015000e+03</td>\n      <td>1.000000e+00</td>\n      <td>5.000000e+01</td>\n      <td>2.015000e+03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.219087e+02</td>\n      <td>1.997391e+00</td>\n      <td>NaN</td>\n      <td>3.849926e+03</td>\n      <td>4.644117e+02</td>\n      <td>3.755392e-01</td>\n      <td>4.857586e-01</td>\n      <td>3.830564e-01</td>\n      <td>8.499262e+03</td>\n      <td>2.847468e+00</td>\n      <td>5.183775e+00</td>\n      <td>4.999999e-01</td>\n      <td>1.532393e+01</td>\n      <td>1.005877e+03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Фичи из даты"
   ],
   "metadata": {
    "id": "KVVOTAWKvWN1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['Year'] = df['Date'].dt.year - 2000\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['CompetitionOpenSinceYear'] -= 2000\n",
    "df.loc[df['Promo2SinceYear'] > 2000, 'Promo2SinceYear'] -= 2000"
   ],
   "metadata": {
    "id": "1IV2pS57u3IF",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:50.350975900Z",
     "start_time": "2024-08-24T10:39:50.209952100Z"
    }
   },
   "execution_count": 274,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "вариант преобразования даты в порядковое для некоторых моделей"
   ],
   "metadata": {
    "id": "egl5inTB7D0A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_cleaned = df.drop(columns=['Date'])"
   ],
   "metadata": {
    "id": "eMMC7j4s7Nu4",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:50.429431700Z",
     "start_time": "2024-08-24T10:39:50.347972900Z"
    }
   },
   "execution_count": 275,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['DateOrdinal'] = df['Date'].map(pd.Timestamp.toordinal)"
   ],
   "metadata": {
    "id": "2ualDFid7ATy",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:52.781678700Z",
     "start_time": "2024-08-24T10:39:50.430430600Z"
    }
   },
   "execution_count": 276,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Можно юзать лаговые и скользящие признаки"
   ],
   "metadata": {
    "id": "Kzm7zS8G7R2H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['Sales_Lag_1'] = df['Sales'].shift(1)\n",
    "df['Sales_Lag_7'] = df['Sales'].shift(7)\n",
    "df['Sales_MA_7'] = df['Sales'].rolling(window=7).mean()\n",
    "df['Sales_MA_30'] = df['Sales'].rolling(window=30).mean()\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "id": "zXNKwNwG7XVa",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:53.099188800Z",
     "start_time": "2024-08-24T10:39:52.783678900Z"
    }
   },
   "execution_count": 277,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сезонное декомпозирование"
   ],
   "metadata": {
    "id": "b4V0Xi-l7hmv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(df['Sales'], model='additive', period=365)\n",
    "df['Trend'] = result.trend\n",
    "df['Seasonal'] = result.seasonal\n",
    "df['Residual'] = result.resid\n",
    "df = df.dropna()\n",
    "print(df.head())\"\"\""
   ],
   "metadata": {
    "id": "ItsZTdCv7lEk",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:53.109214900Z",
     "start_time": "2024-08-24T10:39:53.101179600Z"
    }
   },
   "execution_count": 278,
   "outputs": [
    {
     "data": {
      "text/plain": "\"from statsmodels.tsa.seasonal import seasonal_decompose\\nresult = seasonal_decompose(df['Sales'], model='additive', period=365)\\ndf['Trend'] = result.trend\\ndf['Seasonal'] = result.seasonal\\ndf['Residual'] = result.resid\\ndf = df.dropna()\\nprint(df.head())\""
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Логарифмирование для экспонициальных и трендовых столбцов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Логарифмирование данных\n",
    "df['CompetitionDistance_log'] = np.log(df['CompetitionDistance'] + 1)\n",
    "df = df.drop(columns=['CompetitionDistance'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:53.214053400Z",
     "start_time": "2024-08-24T10:39:53.107222400Z"
    }
   },
   "execution_count": 279
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Нормализация с учетом временных данных (тут чисто пример от гптшки т.к. не успеваю дописать"
   ],
   "metadata": {
    "id": "IRXvXXOm7tFg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 2. Обновление списка категориальных столбцов для кодирования\n",
    "categorical_column = ['StateHoliday', 'StoreType', 'Assortment', 'PromoInterval']\n",
    "\n",
    "# Убедитесь, что все столбцы из списка есть в DataFrame\n",
    "categorical_column = [col for col in categorical_column if col in df.columns]\n",
    "\n",
    "# 3. Факторизация категориальных столбцов\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_df_list = []\n",
    "\n",
    "for name in categorical_column:\n",
    "    # Применение OneHotEncoder к целевому столбцу\n",
    "    encoded_columns = encoder.fit_transform(df[[name]])\n",
    "    # Преобразование закодированных данных в DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out([name]))\n",
    "    encoded_df_list.append(encoded_df)\n",
    "\n",
    "# Объединение закодированных столбцов с исходным DataFrame (удалив при этом исходные столбцы)\n",
    "df = df.drop(columns=categorical_column)\n",
    "df = pd.concat([df] + encoded_df_list, axis=1)\n",
    "\n",
    "# 4. Удаление столбца с датой перед моделированием и анализом корреляций\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "# Убедимся, что результат корректный\n",
    "print(df.head(10))\n"
   ],
   "metadata": {
    "id": "obAvQ0hF7sqd",
    "ExecuteTime": {
     "end_time": "2024-08-24T10:40:48.613355600Z",
     "start_time": "2024-08-24T10:40:47.926899600Z"
    }
   },
   "execution_count": 281,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001B[0m, in \u001B[0;36m_unique_python\u001B[1;34m(values, return_inverse, return_counts)\u001B[0m\n\u001B[0;32m    172\u001B[0m uniques_set, missing_values \u001B[38;5;241m=\u001B[39m _extract_missing(uniques_set)\n\u001B[1;32m--> 174\u001B[0m uniques \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(uniques_set)\n\u001B[0;32m    175\u001B[0m uniques\u001B[38;5;241m.\u001B[39mextend(missing_values\u001B[38;5;241m.\u001B[39mto_list())\n",
      "\u001B[1;31mTypeError\u001B[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[281], line 20\u001B[0m\n\u001B[0;32m     16\u001B[0m encoded_df_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m categorical_column:\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# Применение OneHotEncoder к целевому столбцу\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m     encoded_columns \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# Преобразование закодированных данных в DataFrame\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     encoded_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(encoded_columns, columns\u001B[38;5;241m=\u001B[39mencoder\u001B[38;5;241m.\u001B[39mget_feature_names_out([name]))\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    319\u001B[0m         )\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\base.py:1098\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m   1083\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1084\u001B[0m             (\n\u001B[0;32m   1085\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) has a `transform`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1093\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m   1094\u001B[0m         )\n\u001B[0;32m   1096\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1097\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m   1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:976\u001B[0m, in \u001B[0;36mOneHotEncoder.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    957\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    958\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    959\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    960\u001B[0m \u001B[38;5;124;03m    Fit OneHotEncoder to X.\u001B[39;00m\n\u001B[0;32m    961\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    974\u001B[0m \u001B[38;5;124;03m        Fitted encoder.\u001B[39;00m\n\u001B[0;32m    975\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 976\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhandle_unknown\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_unknown\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_drop_idx()\n\u001B[0;32m    982\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_features_outs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_n_features_outs()\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:99\u001B[0m, in \u001B[0;36m_BaseEncoder._fit\u001B[1;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001B[0m\n\u001B[0;32m     96\u001B[0m Xi \u001B[38;5;241m=\u001B[39m X_list[i]\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcategories \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 99\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_unique\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_counts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compute_counts:\n\u001B[0;32m    101\u001B[0m         cats, counts \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:42\u001B[0m, in \u001B[0;36m_unique\u001B[1;34m(values, return_inverse, return_counts)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03m    array. Only provided if `return_counts` is True.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m values\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_unique_python\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_counts\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# numerical\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _unique_np(\n\u001B[0;32m     47\u001B[0m     values, return_inverse\u001B[38;5;241m=\u001B[39mreturn_inverse, return_counts\u001B[38;5;241m=\u001B[39mreturn_counts\n\u001B[0;32m     48\u001B[0m )\n",
      "File \u001B[1;32mD:\\Valerian\\Documents\\OneDrive\\Python\\ДопОбр Анализ данных\\Практика Нетодология\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:179\u001B[0m, in \u001B[0;36m_unique_python\u001B[1;34m(values, return_inverse, return_counts)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    178\u001B[0m     types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(t\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mtype\u001B[39m(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values))\n\u001B[1;32m--> 179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    180\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncoders require their input argument must be uniformly \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    181\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrings or numbers. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtypes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    182\u001B[0m     )\n\u001B[0;32m    183\u001B[0m ret \u001B[38;5;241m=\u001B[39m (uniques,)\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_inverse:\n",
      "\u001B[1;31mTypeError\u001B[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удаление лишних столбцов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Store\"])\n",
    "df = df.drop(columns=['Customers'])\n",
    "df = df.drop(columns=['Sales_Lag_1'])\n",
    "df = df.drop(columns=['Sales_Lag_7'])\n",
    "df = df.drop(columns=['Sales_MA_7'])\n",
    "df = df.drop(columns=['Sales_MA_30'])\n",
    "#df = df.drop(columns=['Residual'])\n",
    "df = df.drop(columns=['StoreType']) \n",
    "df = df.drop(columns=['DateOrdinal']) \n",
    "# Приведение всех столбцов к числовым значениям\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:53.892540700Z",
     "start_time": "2024-08-24T10:39:53.889544400Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Заменяем NaN на '0'\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(df.info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-24T10:39:53.891539200Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Определяем целевую переменную (в данном случае, допустим, что 'Sales' - это целевая переменная)\n",
    "target = 'Sales'\n",
    "\n",
    "# Разделяем признаки (X) и целевую переменную (y)\n",
    "X = df.drop(columns=[target])\n",
    "Y = df[target]\n",
    "\n",
    "# Разделяем данные на тренировочный и тестовый наборы\n",
    "# Например, тестовый набор составит 20% от всех данных\n",
    "train_points, test_points, train_values, test_values = train_test_split(X, Y, test_size = 0.2)\n",
    "print(train_points.columns)\n",
    "print(train_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-24T10:39:53.892540700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Предположим, что ваши данные уже подготовлены и содержат колонки с лагами и скользящими средними\n",
    "# Например: df содержит 'Sales_Lag_1', 'Sales_Lag_7', 'Sales_MA_7', 'Sales_MA_30' и другие признаки\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Разделение на признаки (X) и целевую переменную (y)\n",
    "X = df.drop(columns=['Sales'])  # Все колонки кроме 'Sales' являются признаками\n",
    "y = df['Sales']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Создаем модель случайного леса с оптимизированными параметрами\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=50,  \n",
    "    max_depth=10,  # Ограничение глубины деревьев для ускорения обучения\n",
    "    n_jobs=-1,  # все доступные ядра процессора\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Вычисление метрик\n",
    "mae_rf = mean_absolute_error(y_test, y_pred)\n",
    "mse_rf = mean_squared_error(y_test, y_pred)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "r2_rf = r2_score(y_test, y_pred)\n",
    "\n",
    "# Вывод значений метрик\n",
    "print(f\"Среднее абсолютное отклонение (MAE) на тестовых данных (RandomForest): {mae_rf}\")\n",
    "print(f\"Среднеквадратичная ошибка (MSE) на тестовых данных (RandomForest): {mse_rf}\")\n",
    "print(f\"Корень средней квадратичной ошибки (RMSE) на тестовых данных (RandomForest): {rmse_rf}\")\n",
    "print(f\"Коэффициент детерминации (R^2) на тестовых данных (RandomForest): {r2_rf}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T10:39:53.896537400Z",
     "start_time": "2024-08-24T10:39:53.895537200Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-24T10:39:53.896537400Z"
    }
   }
  }
 ]
}
